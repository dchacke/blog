---
layout: post
title: "Two Razors for Any Theory of the Mind"
date: 2020-11-13 19:07:44 -0800
tags:
 - philosophy
---

**TL;DR:** *If a theory of the mind depends on sense data or the brain, it cannot be true.*

### So you want to know how to evaluate theories of the mind?

Theories of the mind are a dime a dozen. So how to wade through them all?

First, there's David Deutsch's test "for judging claims to have explained the nature of consciousness (or any other computational task): *if you can't program it, you haven't understood it.*"\
— [*The Beginning of Infinity* (BoI)](https://www.amazon.com/Beginning-Infinity-Explanations-Transform-World/dp/0143121359/)

Nobody can yet program a mind, which tells us that nobody has yet understood how the mind works. Somebody will need to come up with a good explanation of that first.

But until then, how can we judge whether we are even heading in the *right direction*?

Use the following two "razors":

1. **Does the theory work without sense input?**

    Many research efforts are heavily influenced by *empiricism*, a philosophical doctrine which states that knowledge is derived from the senses. As Deutsch explains in BoI chapter 1, this doctrine is completely false. Although papers may not specifically mention empiricism, they are usually variations on the theme of processing sense input, claiming that thinking somehow relies on it.

    Any theory claiming that sense input is necessary for thinking/learning is empiricist and therefore false. Sense input does play a vital role while learning, but not that of being a starting point from which knowledge can be "derived." A mind uses sense input to test guessed theories *against it*. The theories *come first*, then comes a whole lot of critcism (which most theories don't survive), and then comes the testing against sense input (cf. BoI chapter 10).

    But not all of a mind's theories need sense input to be tested. Only theories about what our immediate surroundings look like do. Many of our theories don't involve sense data at all, nor could they: knowledge about morals or math, for example, simply aren't about our immediate surroundings. They're about abstract truths, and we can still criticize them using other yardsticks, such as internal consistency and conflicts with other theories. *Problems* are the starting point, not sense data.

    Therefore, we know that a brain in a vat could still contain a fully functioning mind. It could still conjecture about the world outside itself, albeit only in a very limited way. It could, in principle, still *imagine* things like elephants, even if it had never seen them—though admittedly that would be very difficult. But, more importantly, that mind would be self-aware, it could explore morals and math and philosphy, and invent new fields and explore new concepts we haven't yet thought of. None of the things that make a mind *depend* on sense data.

    Therefore, if a theory of the mind *depends* on sense data to work, it can't be true. This razor alone will let you cut out \~90% of candidate theories of the mind.

2. **Does the theory work without mentioning the underlying hardware (the brain)?**

    Most seem to think that a sufficient understanding of the *brain* will automatically confer an understanding of the *mind*, and perhaps vice versa. But why should that be the case? There is a difference between hardware and software. Understanding how computers work does not automatically make you a programmer, and vice versa.

    At this point, you might raise a finger and say, "but wait, the brain is not really a computer, is it?" Yes, it is. Due to computational universality, any kind of information processing is computation. The brain clearly processes information, so it must be a computer. It really is as simple as that. (And no, information processing does not depend on sense input. The information that's being processed can come from *inside the structure*, it need not come from outside.)

    We also know from computational universality that anything the brain does could be simulated on *any other* universal computer (within memory and processing-power constraints), be it one made of tissue and neurons or one made of metal and silicon. While complex and stunning, the brain's *physiology* has no special or mystical status. There's nothing the brain can do in terms of information processing that any other universal computer (our smartphones and laptops included) couldn't also do. *The mind does not depend on the brain to function—any other universal hardware will do.*

    Overthinking the brain and neglecting the mind is a reductionist mistake. It's reductionist because it is an attempt to explain software (i.e., something abstract) in terms of hardware (i.e., something physical), and because it pictures the causal chain always to go from lower level (the brain) to higher level (the mind). In reality, it's the software that instructs its hardware top down, and there is feedback between both levels of abstraction.

    So, for the remaining \~10% that the first razor didn't cut, use this second razor and you'll find that only 10% of *that* subset make it.

    Deutsch explains the difference between higher and lower levels of emergence as well as the nature of abstractions in chapter 5 of BoI. He covers computational universality in chapter 6. I also write about these concepts [in my book](https://www.amazon.com/Window-Intelligence-Philosophy-Evolution-Implications-dp-1734696133/dp/1734696133).

Theories of the mind often contain many or even all of the misconceptions mentioned in these razors because they make each other more plausible. Researchers may think of the brain as a "special kind of perception machine"—the culmination of everything wrong I have just described—and then think that this will tell them something about the mind. Perhaps this is due to the misconception that a brain's information processing requires sense data as a starting point. Worse, most theories don't make any mention of *creativity*—which is the core of the mind, perhaps synonymous with it. They try to find some pre-existing algorithm for recognizing shapes (or something comparable) that could just as well be executed mindlessly. Thinking that knowledge could be created through the use of existing knowledge is the mistaken evolutionary theory of *Lamarckism*, due to the French naturalist Jean-Baptiste Lamarck.

Which brings me to additional razors. For example, thanks to Karl Popper, we know that the true theory of the mind must employ evolution. So, whatever the algorithm is that runs on our brains that instantiates our minds, it must be an *evolutionary* one. That cuts it down even further. But using the two razors above already cuts out 99% of all theories—at least of the ones I have seen.

Part of taking ideas seriously is to reject them when one finds that they're false. Empiricism, reductionism and violations of computational universality still spread because people don't take them seriously. Once you do, you'll have a much easier time evaluating claims about how the mind works. Many worry they're not qualified to reject theories of the mind. But you've read this article now, so you are. Feel encouraged to reject bad theories wholesale and without remorse. The more you practice using these razors, the more skilled you become at rejecting bad theories quickly. You won't need to read whole essays on perception anymore to see if anything's wrong with them. The mere premise gives it away.

I hope you find these razors useful.
